# Example of accuracy analysis

## Overview

This example uses the shufflenetv2.onnx model as a demonstration to show the usage flow of the RKNN-Toolkit accuracy analysis. And when the post-quantization accuracy is not good, use the hybrid_quantization interface to improve the inference accuracy of the RKNN model. In actual use, please make a certain trade-off between inference accuracy and inference speed according to specific needs.


## Steps for usage

1. Generate conventional quantization RKNN model and generate accuracy analysis report.

   `python normal_quantizition.py`

   - After execution, the normal_quantization_analysis folder can be obtained in the project directory. For the meaning of each file/directory, refer to Chapter 4.3 of "Rockchip_User_Guide_RKNN_Toolkit_CN.docx".
   - From the generated individual_qnt_error_analysis.txt file, you can see that the normalized cosine values ​​of the three layers Conv_418, Conv_434, and Conv_530 are 0.97, 0.98, and 0.96 respectively, which are relatively low compared to other layers and can be considered unfriendly to quantization. These operators can be expressed with high-precision data types (such as int16 or float16) through hybrid quantization. The normalized cosine values ​​of other network layers are all above 0.99, which can be considered quantization-friendly. Record the names of these network layers first for later steps.
   - The default target platform of this script is rv1126. If you want to run the exported RKNN model on rk1808/rk3399pro, you need to specify the target when calling the script, such as: `python normal_quantizition.py rk1808`.


2. Execute hybrid quantization step 1 to generate a quantization configuration file. For details, please refer to Chapter 4.5 of "Rockchip_User_Guide_RKNN_Toolkit_CN.docx".

   `python hybrid_quantization_step1.py`

   - Open the generated torchjitexport.quantization.cfg configuration file, refer to the instructions in Section 4.5 of "Rockchip_User_Guide_RKNN_Toolkit_CN.docx", and add the network layer (obtained from step 1) and the corresponding high-precision data type that you want to use hybrid quantization processing in the customized_quantize_layers information。

   - customized_quantize_layers in the config file will suggest a default hybrid quantization layers. The RKNN model generated according to this suggestion may not be optimal. Please set it flexibly according to the specific model during actual use. The quantization.cfg generated by the example model is recommended for hybrid quantification as follows (different platforms, different versions of tools, the layer names may have some differences)：

     ```
     customized_quantize_layers:
         Reshape_Reshape_614_2: dynamic_fixed_point-i16
         Gemm_Gemm_615_1: dynamic_fixed_point-i16
         AveragePool_AveragePool_612_3: dynamic_fixed_point-i16
         Reshape_Reshape_614_2_acuity_mark_perm_157: dynamic_fixed_point-i16
         Conv_Conv_434_104: dynamic_fixed_point-i16
         Conv_Conv_436_101: dynamic_fixed_point-i16
         Slice_Slice_363_148: dynamic_fixed_point-i16
         Conv_Conv_364_145_acuity_mark_perm_209: dynamic_fixed_point-i16
         Conv_Conv_530_49: dynamic_fixed_point-i16
         Conv_Conv_466_86: dynamic_fixed_point-i16
         Conv_Conv_418_113: dynamic_fixed_point-i16
         Conv_Conv_383_132: dynamic_fixed_point-i16
         Conv_Conv_367_141: dynamic_fixed_point-i16
         Conv_Conv_345_146: dynamic_fixed_point-i16
         Conv_Conv_353_147: dynamic_fixed_point-i16
         Conv_Conv_343_149: dynamic_fixed_point-i16
         Conv_Conv_348_153: dynamic_fixed_point-i16
     ```

     Here we follow the observation results of step 1 and modify it as：

     ```
     customized_quantize_layers:
         Conv_Conv_434_104: dynamic_fixed_point-i16
         Conv_Conv_530_49: dynamic_fixed_point-i16
         Conv_Conv_418_113: dynamic_fixed_point-i16
     ```
   - The default target platform of this script is rv1126. If you want to run the exported RKNN model on rk1808/rk3399pro, you need to specify the target when calling the script, shuc as: `python hybrid_quantization_step1.py rk1808`.


3. Execute the second step of hybrid quantization, recalculate the quantization parameters, and generate a hybrid quantization RKNN model.

   `python hybrid_quantization_step2.py`

   *Note: The default target platform of this script is rv1126. If you want to run the exported RKNN model on rk1808/rk3399pro, you need to specify the target when calling the script, such as: `python hybrid_quantization_step1.py rk1808`.*


4. Compare the classification result scores of the original model, conventional quantization model and hybrid quantization model.

   `python run_onnx_model.py`	

   ```
   -----TOP 5-----
   [155]: 0.9758387804031372
   [154]: 0.02226063795387745
   [364]: 0.00038293670513667166
   [960]: 0.00022784945031162351
   [879]: 0.0001287872582906857
   ```

   `python run_normal_quantization_model.py`

   ```
   -----TOP 5-----
   [155]: 0.9094294309616089
   [154]: 0.06887859851121902
   [364]: 0.0020060015376657248
   [193]: 0.0018231587018817663
   [879]: 0.0012439332203939557
   ```

   `python run_hybrid_quantization_model.py`

   ```
   -----TOP 5-----
   [155]: 0.9504370093345642
   [154]: 0.04463796317577362
   [194 364]: 0.0005500342231243849
   [194 364]: 0.0005500342231243849
   [879]: 0.00041292302194051445
   ```

   - It can be seen that the classification score of the hybrid quantization model has been greatly improved, and is closer to the classification score of the original model. Here users can also try to use the default recommended configuration for hybrid quantization.
   - Different platforms, different versions of tools and drivers may have slightly different results.


## Parameter description for scripts


- normal_quantizition
   ```
   python normal_quantizition.py [target]
   ```
   - target: target platform. Optional parameter, the default value is `rv1126`, you can fill in `rk1806`, `rk1808`, `rk3399pro`, `rv1109`, `rv1126`.


- hybrid_quantization_step1
   ```
   python hybrid_quantization_step1.py [target]
   ```
   - target: target platform. Optional parameter, the default value is `rv1126`, you can fill in `rk1806`, `rk1808`, `rk3399pro`, `rv1109`, `rv1126`.


- hybrid_quantization_step2
   ```
   python hybrid_quantization_step2.py [target]
   ```
   - target: target platform. Optional parameter, the default value is `rv1126`, you can fill in `rk1806`, `rk1808`, `rk3399pro`, `rv1109`, `rv1126`.


- run_normal_quantization_model
   ```
   python run_normal_quantization_model.py [target] [device_id]
   ```
   - target: target platform. Optional parameter, the default value is `rv1126`, you can fill in `rk1806`, `rk1808`, `rk3399pro`, `rv1109`, `rv1126`.
   - device_id: Device ID, when multiple devices are connected, this parameter is used to distinguish them. Optional parameter, default value is None.


- run_hybrid_quantization_model
   ```
   python run_hybrid_quantization_model.py [target] [device_id]
   ```
   - target: target platform. Optional parameter, the default value is `rv1126`, you can fill in `rk1806`, `rk1808`, `rk3399pro`, `rv1109`, `rv1126`.
   - device_id: Device ID, when multiple devices are connected, this parameter is used to distinguish them. Optional parameter, default value is None.
